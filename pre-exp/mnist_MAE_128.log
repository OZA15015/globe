/home/oza/.pyenv/versions/oza2/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/oza/.pyenv/versions/oza2/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
56000
14000
Epoch: 0 train_loss: 102.26034545898438
Epoch: 0 test_loss: 87.47586822509766
Epoch: 1 train_loss: 86.58628845214844
Epoch: 1 test_loss: 85.1554946899414
Epoch: 2 train_loss: 84.9483413696289
Epoch: 2 test_loss: 84.17231750488281
Epoch: 3 train_loss: 83.92558288574219
Epoch: 3 test_loss: 83.07694244384766
Epoch: 4 train_loss: 82.8555679321289
Epoch: 4 test_loss: 82.08555603027344
Epoch: 5 train_loss: 82.00838470458984
Epoch: 5 test_loss: 81.2753677368164
Epoch: 6 train_loss: 81.22920989990234
Epoch: 6 test_loss: 80.52014923095703
Epoch: 7 train_loss: 80.54949951171875
Epoch: 7 test_loss: 80.05451202392578
Epoch: 8 train_loss: 79.993896484375
Epoch: 8 test_loss: 79.4711685180664
Epoch: 9 train_loss: 79.43685150146484
Epoch: 9 test_loss: 79.05188751220703
Epoch: 10 train_loss: 79.07264709472656
Epoch: 10 test_loss: 78.58979034423828
Epoch: 11 train_loss: 78.63946533203125
Epoch: 11 test_loss: 78.09439086914062
Epoch: 12 train_loss: 78.07273864746094
Epoch: 12 test_loss: 77.5572280883789
Epoch: 13 train_loss: 77.59614562988281
Epoch: 13 test_loss: 77.19231414794922
Epoch: 14 train_loss: 77.244384765625
Epoch: 14 test_loss: 76.99848937988281
Epoch: 15 train_loss: 76.97372436523438
Epoch: 15 test_loss: 76.59918212890625
Epoch: 16 train_loss: 76.64752197265625
Epoch: 16 test_loss: 76.31358337402344
Epoch: 17 train_loss: 76.35222625732422
Epoch: 17 test_loss: 76.03370666503906
Epoch: 18 train_loss: 76.10783386230469
Epoch: 18 test_loss: 75.69694519042969
Epoch: 19 train_loss: 75.71420288085938
Epoch: 19 test_loss: 75.64240264892578
Epoch: 20 train_loss: 75.47360229492188
Epoch: 20 test_loss: 75.22347259521484
Epoch: 21 train_loss: 75.26622009277344
Epoch: 21 test_loss: 75.14328002929688
Epoch: 22 train_loss: 75.01351165771484
Epoch: 22 test_loss: 74.80834197998047
Epoch: 23 train_loss: 74.81663513183594
Epoch: 23 test_loss: 74.51781463623047
Epoch: 24 train_loss: 74.52995300292969
Epoch: 24 test_loss: 74.21915435791016
Epoch: 25 train_loss: 74.28189849853516
Epoch: 25 test_loss: 73.9554672241211
Epoch: 26 train_loss: 74.0882797241211
Epoch: 26 test_loss: 74.10514831542969
Epoch: 27 train_loss: 74.01614379882812
Epoch: 27 test_loss: 73.83747863769531
Epoch: 28 train_loss: 73.75541687011719
Epoch: 28 test_loss: 73.48899841308594
Epoch: 29 train_loss: 73.53377532958984
Epoch: 29 test_loss: 73.46965026855469
Epoch: 30 train_loss: 73.41931915283203
Epoch: 30 test_loss: 73.41413116455078
Epoch: 31 train_loss: 73.25881958007812
Epoch: 31 test_loss: 73.12982177734375
Epoch: 32 train_loss: 73.07970428466797
Epoch: 32 test_loss: 72.95929718017578
Epoch: 33 train_loss: 72.94841003417969
Epoch: 33 test_loss: 72.96326446533203
Epoch: 34 train_loss: 72.89865112304688
Epoch: 34 test_loss: 72.81900787353516
Epoch: 35 train_loss: 72.8095474243164
Epoch: 35 test_loss: 72.6580810546875
Epoch: 36 train_loss: 72.61656188964844
Epoch: 36 test_loss: 72.50138092041016
Epoch: 37 train_loss: 72.46018981933594
Epoch: 37 test_loss: 72.41021728515625
Epoch: 38 train_loss: 72.30757141113281
Epoch: 38 test_loss: 72.30591583251953
Epoch: 39 train_loss: 72.23285675048828
Epoch: 39 test_loss: 72.24951171875
Epoch: 40 train_loss: 72.15876007080078
Epoch: 40 test_loss: 72.25953674316406
Epoch: 41 train_loss: 72.02823638916016
Epoch: 41 test_loss: 72.27986907958984
Epoch: 42 train_loss: 71.92859649658203
Epoch: 42 test_loss: 72.06037902832031
Epoch: 43 train_loss: 71.7868423461914
Epoch: 43 test_loss: 71.79411315917969
Epoch: 44 train_loss: 71.64163208007812
Epoch: 44 test_loss: 71.81079864501953
Epoch: 45 train_loss: 71.5371322631836
Epoch: 45 test_loss: 71.84494018554688
Epoch: 46 train_loss: 71.55384063720703
Epoch: 46 test_loss: 71.83072662353516
Epoch: 47 train_loss: 71.45157623291016
Epoch: 47 test_loss: 71.60548400878906
Epoch: 48 train_loss: 71.36180877685547
Epoch: 48 test_loss: 71.55457305908203
Epoch: 49 train_loss: 71.22543334960938
Epoch: 49 test_loss: 71.4126968383789
